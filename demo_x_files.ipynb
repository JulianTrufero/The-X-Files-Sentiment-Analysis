{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import spacy\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import sqlalchemy as alch\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = 'Admin123.'\n",
    "dbName=\"thexfiles\"\n",
    "connectionData=f\"mysql+pymysql://root:{password}@localhost/{dbName}\"\n",
    "engine = alch.create_engine(connectionData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the csv files with the scripts from each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot = pd.read_csv('/home/julian/Cursos/Ironhack/Proyectos/Proyecto4/The-X-Files-Sentiment-Analysis/Data/pilot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_1 = pd.read_csv('/home/julian/Cursos/Ironhack/Proyectos/Proyecto4/The-X-Files-Sentiment-Analysis/Data/episode_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_2 = pd.read_csv('/home/julian/Cursos/Ironhack/Proyectos/Proyecto4/The-X-Files-Sentiment-Analysis/Data/episode_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtengo los scripts mediante la func script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def script(csv):\n",
    "    p_1 = csv.to_dict()\n",
    "    p_2 = p_1.values()\n",
    "    p_3 = list(list(p_2)[0].values())\n",
    "    return p_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = [pilot, episode_1, episode_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = [script(e) for e in episodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creo un data frame de frases por personaje para cada script mediante la func phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = ['Scully', 'Mulder']\n",
    "regs = ['\\SCULLY\\S.*', '\\SULDER\\S.*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrases(character, script, reg):\n",
    "    plist = []\n",
    "    for s in script:\n",
    "        match = re.findall(f'{reg}', s)\n",
    "        if match:\n",
    "            plist.append(s)\n",
    "    p_dic = {f'{character}': [i[8:] for i in plist]}\n",
    "    p_phrases = pd.DataFrame(p_dic)\n",
    "    return p_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for s in scripts:\n",
    "    for c, r in zip(characters, regs):\n",
    "        df = phrases(c, s, r)\n",
    "        df[f'{c}'] = df[f'{c}'].str.replace(\"'\", ' ')\n",
    "        df[f'{c}'] = df[f'{c}'].str.replace('\"', ' ')\n",
    "        df[f'{c}'] = df[f'{c}'].str.replace(\"%\", ' ')\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's insert our main characters in the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploadcharacter(character):\n",
    "    upload = engine.execute(f\"\"\" INSERT INTO Characters (`Character`) VALUES ('{character}');\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's insert the character's phrases into the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploadphrases(df):\n",
    "    for i, fila in df.iterrows():\n",
    "        print(fila)\n",
    "\n",
    "#    engine.execute(\n",
    " #       f\"\"\"\n",
    "  #      INSERT INTO Phrases (Phrase, Characters_idCharacters, Episodes_idEpisodes)\n",
    "   #     VALUES (\"{fila['Scully']}\", 1, 3);\n",
    "    #    \"\"\"\n",
    "     #   )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-37-5c23cada45ee>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-37-5c23cada45ee>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    engine.execute(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "for i, fila in scully_e_2.iterrows():\n",
    "    engine.execute(\n",
    "        f\"\"\"\n",
    "        INSERT INTO Phrases (Phrase, Characters_idCharacters, Episodes_idEpisodes) VALUES (\"{fila['Scully']}\", 1, 3);\n",
    "       \"\"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This phrase doesn`t exist'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modifyphrase('Fallen Angel','mulder','this is test','this is modification test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = {\"episode\": \"Fallen Angel\", \"character\": \"mulder\", \"phrase\": \"this is modification test\", \"modification\": \"this is another modification test\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://127.0.0.1:5000/modphrase'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = requests.post(url, data=frase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OJO ACA, POR QUE NO SALE EL RETURN? PERO SI SE CARGA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FALTA: ENDPOINT SENTIMENT, ORGANIZAR LOS FICHEROS, READ ME's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Agent Dana Scully.']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dfs[0].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity(dfs[0].loc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(txt):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    tokens = nlp(txt)\n",
    "    filtradas = []\n",
    "    \n",
    "    for word in tokens:\n",
    "        if not word.is_stop:\n",
    "            lemma = word.lemma_.lower().strip()\n",
    "            if re.search('^[a-zA-Z]+$',lemma):\n",
    "                filtradas.append(lemma)\n",
    "            \n",
    "    return \" \".join(filtradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity(phrase):\n",
    "    blob = TextBlob(f\"{phrase}\")\n",
    "    \n",
    "    return blob.sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarities = []\n",
    "for i, fila in dfs[0].iterrows():\n",
    "    t = tokenizer(fila[0])\n",
    "    p = polarity(t)\n",
    "    polarities.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.01666666666666668,\n",
       " -0.05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.18055555555555558,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.09,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0050000000000000044,\n",
       " 0.0,\n",
       " -0.02976190476190476,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.16190476190476188,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.8,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.26666666666666666,\n",
       " 0.012499999999999997,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.8,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.6,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.1,\n",
       " 0.4,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.6,\n",
       " 0.0,\n",
       " 0.375,\n",
       " 0.0,\n",
       " 0.2857142857142857,\n",
       " 0.0,\n",
       " 0.4,\n",
       " 0.05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironcon",
   "language": "python",
   "name": "ironcon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
